//! Integration tests for the ReasoningEngine.
//!
//! These tests use a MockLlmClient that returns configurable responses,
//! allowing us to test the full think() pipeline without real LLM calls.

use anyhow::Result;
use async_trait::async_trait;
use mneme_core::{Content, Event, Memory, Modality, Psyche, Reasoning};
use mneme_reasoning::api_types::{ContentBlock, MessagesResponse};
use mneme_reasoning::engine::ReasoningEngine;
use mneme_reasoning::llm::{CompletionParams, LlmClient};
use std::sync::{
    atomic::{AtomicUsize, Ordering},
    Arc,
};
use tokio::sync::Mutex;
use uuid::Uuid;

// ============================================================================
// Mock LLM Client
// ============================================================================

/// A mock LLM client that returns a sequence of pre-configured responses.
/// Each call to `complete()` pops the next response from the queue.
/// If the queue is exhausted, returns a default "empty" response.
struct MockLlmClient {
    responses: Mutex<Vec<MessagesResponse>>,
    call_count: AtomicUsize,
}

impl MockLlmClient {
    fn new(responses: Vec<MessagesResponse>) -> Self {
        Self {
            responses: Mutex::new(responses),
            call_count: AtomicUsize::new(0),
        }
    }

    /// Create a client that always returns a simple text response.
    fn with_text(text: &str) -> Self {
        // Return the same text for both the main call and the extraction call
        Self::new(vec![
            text_response(text),
            // Extraction call returns empty facts
            text_response(r#"{"facts": []}"#),
        ])
    }

    #[allow(dead_code)]
    fn calls(&self) -> usize {
        self.call_count.load(Ordering::SeqCst)
    }
}

#[async_trait]
impl LlmClient for MockLlmClient {
    async fn complete(
        &self,
        _system: &str,
        _messages: Vec<mneme_reasoning::api_types::Message>,
        _tools: Vec<mneme_reasoning::api_types::Tool>,
        _params: CompletionParams,
    ) -> Result<MessagesResponse> {
        self.call_count.fetch_add(1, Ordering::SeqCst);
        let mut queue = self.responses.lock().await;
        if queue.is_empty() {
            Ok(text_response(""))
        } else {
            Ok(queue.remove(0))
        }
    }
}

// ============================================================================
// Mock Memory
// ============================================================================

/// A simple in-memory mock that records what was memorized.
struct MockMemory {
    memorized: Mutex<Vec<Content>>,
    stored_facts: Mutex<Vec<(String, String, String, f32)>>,
}

impl MockMemory {
    fn new() -> Self {
        Self {
            memorized: Mutex::new(Vec::new()),
            stored_facts: Mutex::new(Vec::new()),
        }
    }
}

#[async_trait]
impl Memory for MockMemory {
    async fn recall(&self, _query: &str) -> Result<String> {
        Ok("No relevant memories found.".to_string())
    }

    async fn memorize(&self, content: &Content) -> Result<()> {
        self.memorized.lock().await.push(content.clone());
        Ok(())
    }

    async fn recall_facts_formatted(&self, _query: &str) -> Result<String> {
        Ok(String::new())
    }

    async fn store_fact(
        &self,
        subject: &str,
        predicate: &str,
        object: &str,
        confidence: f32,
    ) -> Result<()> {
        self.stored_facts.lock().await.push((
            subject.to_string(),
            predicate.to_string(),
            object.to_string(),
            confidence,
        ));
        Ok(())
    }
}

// ============================================================================
// Mock Executor
// ============================================================================

struct MockExecutor {
    output: String,
}

impl MockExecutor {
    fn new(output: &str) -> Self {
        Self {
            output: output.to_string(),
        }
    }
}

#[async_trait]
impl mneme_os::Executor for MockExecutor {
    async fn execute(&self, _command: &str) -> Result<String> {
        Ok(self.output.clone())
    }

    fn name(&self) -> &str {
        "mock"
    }
}

// ============================================================================
// Helper functions
// ============================================================================

fn text_response(text: &str) -> MessagesResponse {
    MessagesResponse {
        content: vec![ContentBlock::Text {
            text: text.to_string(),
        }],
        stop_reason: Some("end_turn".to_string()),
        usage: None,
    }
}

/// Helper: create a text response containing a <tool_call> tag (text-only tool path).
fn text_tool_call(name: &str, input: serde_json::Value) -> MessagesResponse {
    let json = serde_json::json!({"name": name, "arguments": input});
    text_response(&format!("<tool_call>{}</tool_call>", json))
}

/// Helper: text response with both prose and a <tool_call> tag.
fn text_with_tool_call(prose: &str, name: &str, input: serde_json::Value) -> MessagesResponse {
    let json = serde_json::json!({"name": name, "arguments": input});
    text_response(&format!("{} <tool_call>{}</tool_call>", prose, json))
}

fn test_psyche() -> Psyche {
    Psyche::with_self_model("Test self model for unit tests.".into())
}

fn user_event(text: &str) -> Event {
    Event::UserMessage(Content {
        id: Uuid::new_v4(),
        source: "test".into(),
        author: "user".into(),
        body: text.into(),
        timestamp: 0,
        modality: Modality::Text,
    })
}

fn build_engine(client: MockLlmClient) -> ReasoningEngine {
    let memory: Arc<dyn Memory> = Arc::new(MockMemory::new());
    let executor: Arc<dyn mneme_os::Executor> = Arc::new(MockExecutor::new("mock output"));
    ReasoningEngine::new(test_psyche(), memory, Box::new(client), executor)
}

fn build_engine_with_mocks(
    client: MockLlmClient,
    memory: Arc<MockMemory>,
    executor: Arc<dyn mneme_os::Executor>,
) -> ReasoningEngine {
    ReasoningEngine::new(
        test_psyche(),
        memory as Arc<dyn Memory>,
        Box::new(client),
        executor,
    )
}

// ============================================================================
// Tests: Basic Conversation
// ============================================================================

#[tokio::test]
async fn test_simple_text_response() {
    let engine = build_engine(MockLlmClient::with_text("ä½ å¥½å‘€ï¼"));
    let result = engine.think(user_event("ä½ å¥½")).await.unwrap();

    assert_eq!(result.content, "ä½ å¥½å‘€ï¼");
    assert!(!result.content.is_empty());
}

#[tokio::test]
async fn test_empty_response_is_silent() {
    let engine = build_engine(MockLlmClient::with_text(""));
    let result = engine.think(user_event("ä½ å¥½")).await.unwrap();

    // Empty content after sanitization
    assert!(result.content.is_empty());
}

#[tokio::test]
async fn test_silence_tag_produces_empty_response() {
    let engine = build_engine(MockLlmClient::with_text("[SILENCE]"));
    let result = engine.think(user_event("å¤§å®¶å¥½")).await.unwrap();

    assert!(
        result.content.is_empty(),
        "SILENCE tag should produce empty content"
    );
}

// ============================================================================
// Tests: Output Sanitization
// ============================================================================

#[tokio::test]
async fn test_roleplay_asterisks_stripped() {
    let engine = build_engine(MockLlmClient::with_text("*å¹äº†å£æ°”*ä½ è¯´å¾—å¯¹"));
    let result = engine.think(user_event("æµ‹è¯•")).await.unwrap();

    assert!(
        !result.content.contains('*'),
        "Roleplay asterisks should be stripped"
    );
    assert!(result.content.contains("ä½ è¯´å¾—å¯¹"));
}

#[tokio::test]
async fn test_markdown_bold_stripped() {
    let engine = build_engine(MockLlmClient::with_text("è¿™æ˜¯**é‡è¦**çš„äº‹æƒ…"));
    let result = engine.think(user_event("æµ‹è¯•")).await.unwrap();

    assert!(
        !result.content.contains("**"),
        "Bold markdown should be stripped"
    );
    assert!(result.content.contains("é‡è¦"));
}

#[tokio::test]
async fn test_markdown_headers_stripped() {
    let engine = build_engine(MockLlmClient::with_text("# æ ‡é¢˜\nå†…å®¹åœ¨è¿™é‡Œ"));
    let result = engine.think(user_event("æµ‹è¯•")).await.unwrap();

    assert!(
        !result.content.starts_with('#'),
        "Headers should be stripped"
    );
    assert!(result.content.contains("æ ‡é¢˜"));
    assert!(result.content.contains("å†…å®¹åœ¨è¿™é‡Œ"));
}

#[tokio::test]
async fn test_markdown_bullets_stripped() {
    let engine = build_engine(MockLlmClient::with_text("- ç¬¬ä¸€\n- ç¬¬äºŒ\n- ç¬¬ä¸‰"));
    let result = engine.think(user_event("æµ‹è¯•")).await.unwrap();

    assert!(
        !result.content.contains("- "),
        "Bullet markers should be stripped"
    );
    assert!(result.content.contains("ç¬¬ä¸€"));
}

// ============================================================================
// Tests: Emotion Parsing
// ============================================================================

#[tokio::test]
async fn test_emotion_tag_parsed_and_stripped() {
    let engine = build_engine(MockLlmClient::with_text(
        "<emotion>Happy</emotion>ä»Šå¤©çœŸå¼€å¿ƒï¼",
    ));
    let result = engine.think(user_event("ä½ å¥½")).await.unwrap();

    // Emotion tag should be stripped from content
    assert!(!result.content.contains("<emotion>"));
    assert!(result.content.contains("ä»Šå¤©çœŸå¼€å¿ƒ"));
    // Emotion should be parsed
    assert_eq!(result.emotion, mneme_core::Emotion::Happy);
}

#[tokio::test]
async fn test_emotion_tag_case_insensitive() {
    let engine = build_engine(MockLlmClient::with_text("<EMOTION>Sad</EMOTION>å‘œå‘œ"));
    let result = engine.think(user_event("ä½ å¥½")).await.unwrap();

    assert!(!result.content.contains("EMOTION"));
    assert!(result.content.contains("å‘œå‘œ"));
}

// ============================================================================
// Tests: Tool Use (ReAct Loop)
// ============================================================================

#[tokio::test]
async fn test_single_tool_call() {
    // Turn 1: LLM requests shell tool
    // Turn 2: LLM produces final text after seeing tool result
    // Turn 3: Extraction call
    let client = MockLlmClient::new(vec![
        text_tool_call("shell", serde_json::json!({"command": "echo hello"})),
        text_response("å‘½ä»¤æ‰§è¡Œå®Œæ¯•ï¼Œç»“æœæ˜¯ hello"),
        text_response(r#"{"facts": []}"#), // extraction
    ]);

    let executor = Arc::new(MockExecutor::new("hello\n"));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor);

    let result = engine.think(user_event("æ‰§è¡Œ echo hello")).await.unwrap();

    assert!(result.content.contains("hello") || result.content.contains("å‘½ä»¤"));
}

#[tokio::test]
async fn test_multi_turn_tool_calls() {
    // Turn 1: First tool call
    // Turn 2: Second tool call
    // Turn 3: Final text response
    // Turn 4: Extraction
    let client = MockLlmClient::new(vec![
        text_tool_call("shell", serde_json::json!({"command": "ls"})),
        text_tool_call("shell", serde_json::json!({"command": "cat file.txt"})),
        text_response("æ–‡ä»¶å†…å®¹æ˜¯ hello world"),
        text_response(r#"{"facts": []}"#),
    ]);

    let executor = Arc::new(MockExecutor::new("result"));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory.clone(), executor);

    let result = engine.think(user_event("è¯»å–æ–‡ä»¶")).await.unwrap();

    assert!(result.content.contains("hello world"));
}

#[tokio::test]
async fn test_react_loop_max_iterations() {
    // LLM keeps requesting tools forever â€” should be capped at 5 iterations
    let mut responses = Vec::new();
    for _i in 0..10 {
        responses.push(text_tool_call(
            "shell",
            serde_json::json!({"command": "loop"}),
        ));
    }
    // After the loop exits, extraction call
    responses.push(text_response(r#"{"facts": []}"#));

    let client = MockLlmClient::new(responses);
    let executor = Arc::new(MockExecutor::new("looped"));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor);

    let result = engine.think(user_event("æ— é™å¾ªç¯")).await.unwrap();

    // Should have been called at most 5 times for the main loop + 1 for extraction
    // (the loop has 5 iterations max, each consumes one response)
    // Content might be empty since we never got a text response
    assert!(result.content.is_empty() || !result.content.is_empty()); // shouldn't panic
}

#[tokio::test]
async fn test_unknown_tool_returns_error_message() {
    // LLM requests an unknown tool, then gives a text response
    let client = MockLlmClient::new(vec![
        text_tool_call("nonexistent_tool", serde_json::json!({})),
        text_response("å¥½çš„æˆ‘ç†è§£äº†"),
        text_response(r#"{"facts": []}"#),
    ]);

    let engine = build_engine(client);
    let result = engine.think(user_event("æµ‹è¯•")).await.unwrap();

    // Should not panic; unknown tool returns "Unknown Tool: ..." and loop continues
    assert!(!result.content.is_empty());
}

#[tokio::test]
async fn test_tool_use_with_text_in_same_response() {
    // Some LLMs return text + tool_use in the same response
    let client = MockLlmClient::new(vec![
        text_with_tool_call(
            "æˆ‘æ¥çœ‹çœ‹ç°åœ¨å‡ ç‚¹",
            "shell",
            serde_json::json!({"command": "date"}),
        ),
        text_response("ç°åœ¨æ˜¯ä¸‹åˆä¸‰ç‚¹"),
        text_response(r#"{"facts": []}"#),
    ]);

    let executor = Arc::new(MockExecutor::new("2026-02-06"));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor);

    let result = engine.think(user_event("å‡ ç‚¹äº†")).await.unwrap();

    assert!(result.content.contains("ä¸‰ç‚¹"));
}

// ============================================================================
// Tests: Memory Integration
// ============================================================================

#[tokio::test]
async fn test_user_message_is_memorized() {
    let memory = Arc::new(MockMemory::new());
    let executor = Arc::new(MockExecutor::new(""));
    let client = MockLlmClient::with_text("æ”¶åˆ°");

    let engine = build_engine_with_mocks(client, memory.clone(), executor);
    engine.think(user_event("è®°ä½è¿™å¥è¯")).await.unwrap();

    let memorized = memory.memorized.lock().await;
    assert_eq!(memorized.len(), 1);
    assert_eq!(memorized[0].body, "è®°ä½è¿™å¥è¯");
}

#[tokio::test]
async fn test_fact_extraction_stores_results() {
    // Main response + extraction response with actual facts
    let client = MockLlmClient::new(vec![
        text_response("æˆ‘çŸ¥é“äº†ä½ å–œæ¬¢çŒ«"),
        text_response(
            r#"{"facts": [{"subject": "ç”¨æˆ·", "predicate": "å–œæ¬¢", "object": "çŒ«", "confidence": 0.9}]}"#,
        ),
    ]);

    let memory = Arc::new(MockMemory::new());
    let executor = Arc::new(MockExecutor::new(""));
    let engine = build_engine_with_mocks(client, memory.clone(), executor);

    engine.think(user_event("æˆ‘å¾ˆå–œæ¬¢çŒ«")).await.unwrap();

    let facts = memory.stored_facts.lock().await;
    assert_eq!(facts.len(), 1);
    assert_eq!(facts[0].0, "ç”¨æˆ·"); // subject
    assert_eq!(facts[0].1, "å–œæ¬¢"); // predicate
    assert_eq!(facts[0].2, "çŒ«"); // object
}

// ============================================================================
// Tests: History Management
// ============================================================================

#[tokio::test]
async fn test_history_accumulates_across_turns() {
    // Use a client with enough responses for 3 conversations
    let client = MockLlmClient::new(vec![
        text_response("å›å¤1"),
        text_response(r#"{"facts": []}"#),
        text_response("å›å¤2"),
        text_response(r#"{"facts": []}"#),
        text_response("å›å¤3"),
        text_response(r#"{"facts": []}"#),
    ]);

    let engine = build_engine(client);

    engine.think(user_event("æ¶ˆæ¯1")).await.unwrap();
    engine.think(user_event("æ¶ˆæ¯2")).await.unwrap();
    engine.think(user_event("æ¶ˆæ¯3")).await.unwrap();

    // We can't directly inspect history, but we can verify it didn't crash
    // and that the 3rd response still works (implicitly tests history assembly)
}

#[tokio::test]
async fn test_history_prune_at_limit() {
    // Send more than 20 messages (10 turns) to trigger pruning
    let mut responses = Vec::new();
    for _ in 0..15 {
        responses.push(text_response("ok"));
        responses.push(text_response(r#"{"facts": []}"#));
    }

    let client = MockLlmClient::new(responses);
    let engine = build_engine(client);

    for i in 0..15 {
        let result = engine.think(user_event(&format!("æ¶ˆæ¯{}", i))).await;
        assert!(result.is_ok(), "Turn {} should succeed after pruning", i);
    }

    // If pruning logic is broken, this would have panicked
}

// ============================================================================
// Tests: Proactive Triggers
// ============================================================================

#[tokio::test]
async fn test_proactive_trigger_scheduled() {
    let client = MockLlmClient::new(vec![
        text_response("æ—©ä¸Šå¥½ï¼æ–°çš„ä¸€å¤©å¼€å§‹äº†"),
        // No extraction for proactive triggers (not a UserMessage)
    ]);

    let engine = build_engine(client);

    let event = Event::ProactiveTrigger(mneme_core::Trigger::Scheduled {
        name: "morning_greeting".into(),
        schedule: "0 8 * * *".into(),
    });

    let result = engine.think(event).await.unwrap();
    assert!(result.content.contains("æ—©ä¸Šå¥½") || !result.content.is_empty());
}

#[tokio::test]
async fn test_proactive_trigger_memory_decay() {
    let client = MockLlmClient::new(vec![text_response(
        "å¯¹äº†ï¼Œä½ ä¹‹å‰æåˆ°è¿‡çš„æ—…è¡Œè®¡åˆ’æ€ä¹ˆæ ·äº†ï¼Ÿ",
    )]);

    let engine = build_engine(client);

    let event = Event::ProactiveTrigger(mneme_core::Trigger::MemoryDecay {
        topic: "æ—…è¡Œè®¡åˆ’".into(),
        last_mentioned: 0,
    });

    let result = engine.think(event).await.unwrap();
    assert!(!result.content.is_empty());
}

// ============================================================================
// Tests: Edge Cases
// ============================================================================

#[tokio::test]
async fn test_multiline_response_preserved() {
    let engine = build_engine(MockLlmClient::with_text("ç¬¬ä¸€è¡Œ\nç¬¬äºŒè¡Œ\nç¬¬ä¸‰è¡Œ"));
    let result = engine.think(user_event("æµ‹è¯•")).await.unwrap();

    assert!(result.content.contains('\n'));
    assert!(result.content.contains("ç¬¬ä¸€è¡Œ"));
    assert!(result.content.contains("ç¬¬ä¸‰è¡Œ"));
}

#[tokio::test]
async fn test_very_long_input_does_not_panic() {
    let long_input = "å•Š".repeat(10_000);
    let engine = build_engine(MockLlmClient::with_text("æ”¶åˆ°äº†"));
    let result = engine.think(user_event(&long_input)).await.unwrap();

    assert!(!result.content.is_empty());
}

#[tokio::test]
async fn test_unicode_emoji_handled() {
    let engine = build_engine(MockLlmClient::with_text("ğŸ˜Šâ¤ï¸ğŸ‰"));
    let result = engine.think(user_event("å‘ä¸ªè¡¨æƒ…")).await.unwrap();

    assert!(result.content.contains("ğŸ˜Š"));
    assert!(result.content.contains("â¤ï¸"));
}

#[tokio::test]
async fn test_shell_tool_missing_command_param() {
    // LLM calls shell tool without required "command" param
    let client = MockLlmClient::new(vec![
        text_tool_call("shell", serde_json::json!({})),
        text_response("å‚æ•°æœ‰è¯¯"),
        text_response(r#"{"facts": []}"#),
    ]);

    let engine = build_engine(client);
    let result = engine.think(user_event("æ‰§è¡Œå‘½ä»¤")).await.unwrap();

    // Should gracefully handle missing param without panic
    assert!(!result.content.is_empty());
}

// ============================================================================
// Tests: Structured Tool Error Handling (#2)
// ============================================================================

/// A mock executor that can simulate different failure modes.
struct FailingExecutor {
    /// How many calls fail before succeeding.
    fail_count: AtomicUsize,
    /// Error message to use.
    error_msg: String,
    /// Output on success.
    success_output: String,
}

impl FailingExecutor {
    /// Always fails with the given message.
    fn always_fail(msg: &str) -> Self {
        Self {
            fail_count: AtomicUsize::new(usize::MAX),
            error_msg: msg.to_string(),
            success_output: String::new(),
        }
    }

    /// Fails `n` times, then succeeds with `output`.
    fn fail_then_succeed(n: usize, msg: &str, output: &str) -> Self {
        Self {
            fail_count: AtomicUsize::new(n),
            error_msg: msg.to_string(),
            success_output: output.to_string(),
        }
    }
}

#[async_trait]
impl mneme_os::Executor for FailingExecutor {
    async fn execute(&self, _command: &str) -> Result<String> {
        let remaining = self.fail_count.load(Ordering::SeqCst);
        if remaining > 0 {
            self.fail_count.fetch_sub(1, Ordering::SeqCst);
            anyhow::bail!("{}", self.error_msg);
        }
        Ok(self.success_output.clone())
    }

    fn name(&self) -> &str {
        "failing_mock"
    }
}

#[tokio::test]
async fn test_shell_timeout_returns_is_error_true() {
    // Shell times out â†’ LLM sees is_error=true with descriptive message
    let client = MockLlmClient::new(vec![
        text_tool_call("shell", serde_json::json!({"command": "sleep 100"})),
        text_response("å‘½ä»¤è¶…æ—¶äº†ï¼Œæˆ‘æ¢ä¸ªæ–¹å¼"),
        text_response(r#"{"facts": []}"#),
    ]);

    let executor = Arc::new(FailingExecutor::always_fail(
        "Command execution timed out after 30s",
    ));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor as Arc<dyn mneme_os::Executor>);

    let result = engine.think(user_event("æ‰§è¡Œå¾ˆä¹…çš„å‘½ä»¤")).await.unwrap();

    // The LLM received the error and produced a recovery response
    assert!(!result.content.is_empty());
}

#[tokio::test]
async fn test_shell_permanent_failure_returns_is_error() {
    // Shell command fails with non-zero exit (permanent) â€” no retry
    let client = MockLlmClient::new(vec![
        text_tool_call("shell", serde_json::json!({"command": "bad_cmd"})),
        text_response("å‘½ä»¤æ‰§è¡Œå¤±è´¥äº†"),
        text_response(r#"{"facts": []}"#),
    ]);

    let executor = Arc::new(FailingExecutor::always_fail(
        "Command failed with status exit code: 127",
    ));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor as Arc<dyn mneme_os::Executor>);

    let result = engine.think(user_event("æ‰§è¡Œé”™è¯¯å‘½ä»¤")).await.unwrap();

    // Should recover gracefully
    assert!(result.content.contains("å¤±è´¥"));
}

#[tokio::test]
async fn test_shell_transient_retry_succeeds() {
    // First call times out (transient), retry succeeds
    let client = MockLlmClient::new(vec![
        text_tool_call("shell", serde_json::json!({"command": "echo ok"})),
        text_response("å‘½ä»¤æ‰§è¡ŒæˆåŠŸ"),
        text_response(r#"{"facts": []}"#),
    ]);

    let executor = Arc::new(FailingExecutor::fail_then_succeed(
        1,
        "Command execution timed out after 30s",
        "ok\n",
    ));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor as Arc<dyn mneme_os::Executor>);

    let result = engine.think(user_event("æ‰§è¡Œå‘½ä»¤")).await.unwrap();

    assert!(result.content.contains("æˆåŠŸ"));
}

#[tokio::test]
async fn test_unknown_tool_is_permanent_error() {
    // Unknown tool should be permanent (not retried)
    let client = MockLlmClient::new(vec![
        text_tool_call("flying_car", serde_json::json!({})),
        text_response("æˆ‘æ²¡æœ‰é‚£ä¸ªå·¥å…·"),
        text_response(r#"{"facts": []}"#),
    ]);

    let engine = build_engine(client);
    let result = engine.think(user_event("å‘å°„é£èˆ¹")).await.unwrap();

    assert!(!result.content.is_empty());
}

#[tokio::test]
async fn test_browser_missing_url_is_permanent_error() {
    // browser_goto without url â†’ permanent error, no retry
    let client = MockLlmClient::new(vec![
        text_tool_call("browser_goto", serde_json::json!({})),
        text_response("ç¼ºå°‘ç½‘å€å‚æ•°"),
        text_response(r#"{"facts": []}"#),
    ]);

    let engine = build_engine(client);
    let result = engine.think(user_event("æ‰“å¼€ç½‘é¡µ")).await.unwrap();

    assert!(!result.content.is_empty());
}

#[tokio::test]
async fn test_browser_missing_selector_is_permanent_error() {
    // browser_click without selector â†’ permanent error
    let client = MockLlmClient::new(vec![
        text_tool_call("browser_click", serde_json::json!({})),
        text_response("ç¼ºå°‘é€‰æ‹©å™¨"),
        text_response(r#"{"facts": []}"#),
    ]);

    let engine = build_engine(client);
    let result = engine.think(user_event("ç‚¹å‡»æŒ‰é’®")).await.unwrap();

    assert!(!result.content.is_empty());
}

#[tokio::test]
async fn test_browser_type_missing_text_is_permanent_error() {
    // browser_type with selector but no text â†’ permanent error
    let client = MockLlmClient::new(vec![
        text_tool_call("browser_type", serde_json::json!({"selector": "#input"})),
        text_response("å‚æ•°ä¸å®Œæ•´"),
        text_response(r#"{"facts": []}"#),
    ]);

    let engine = build_engine(client);
    let result = engine.think(user_event("è¾“å…¥æ–‡å­—")).await.unwrap();

    assert!(!result.content.is_empty());
}

#[tokio::test]
async fn test_tool_error_does_not_crash_react_loop() {
    // Tool fails but the ReAct loop should still continue
    // Turn 1: shell fails, Turn 2: LLM tries again, Turn 3: success, Turn 4: final text
    let client = MockLlmClient::new(vec![
        text_tool_call("shell", serde_json::json!({"command": "fail"})),
        text_tool_call("shell", serde_json::json!({"command": "echo ok"})),
        text_response("ç¬¬äºŒæ¬¡å°±å¥½äº†"),
        text_response(r#"{"facts": []}"#),
    ]);

    // First call fails, second succeeds
    let executor = Arc::new(FailingExecutor::fail_then_succeed(
        1,
        "Command failed with status exit code: 1",
        "ok\n",
    ));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor as Arc<dyn mneme_os::Executor>);

    let result = engine.think(user_event("å°è¯•å‘½ä»¤")).await.unwrap();

    // The LLM should have recovered after getting the error
    assert!(result.content.contains("ç¬¬äºŒæ¬¡") || !result.content.is_empty());
}

#[tokio::test]
async fn test_spawn_failure_is_transient() {
    // "spawn" in error message â†’ transient, will retry
    let client = MockLlmClient::new(vec![
        text_tool_call("shell", serde_json::json!({"command": "echo ok"})),
        text_response("æœ€ç»ˆæˆåŠŸäº†"),
        text_response(r#"{"facts": []}"#),
    ]);

    let executor = Arc::new(FailingExecutor::fail_then_succeed(
        1,
        "Failed to spawn command locally",
        "ok\n",
    ));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor as Arc<dyn mneme_os::Executor>);

    let result = engine.think(user_event("æ‰§è¡Œ")).await.unwrap();

    assert!(!result.content.is_empty());
}

// ============================================================================
// Tests: Text Tool Call Parsing (always active)
// ============================================================================

#[tokio::test]
async fn test_text_mode_parses_tool_call_tag() {
    // In Text mode, model returns <tool_call> in plain text instead of structured ToolUse.
    // Turn 1: Model outputs text with <tool_call> tag â†’ engine parses and executes shell
    // Turn 2: Model sees tool result as plain text, produces final response
    // Turn 3: Extraction
    let client = MockLlmClient::new(vec![
        text_response(
            "æˆ‘æ¥çœ‹çœ‹ <tool_call>{\"name\":\"shell\",\"arguments\":{\"command\":\"ls -la\"}}</tool_call>"
        ),
        text_response("å½“å‰ç›®å½•æœ‰è¿™äº›æ–‡ä»¶ï¼šfile1.txt file2.rs"),
        text_response(r#"{"facts": []}"#),
    ]);

    let executor = Arc::new(MockExecutor::new("file1.txt\nfile2.rs\n"));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor);

    let result = engine.think(user_event("çœ‹çœ‹å½“å‰ç›®å½•")).await.unwrap();

    assert!(result.content.contains("file1.txt") || result.content.contains("æ–‡ä»¶"));
}

#[tokio::test]
async fn test_text_mode_strips_tool_call_from_content() {
    // The <tool_call> tag should be stripped from the displayed content
    let client = MockLlmClient::new(vec![
        text_response(
            "å¥½çš„ <tool_call>{\"name\":\"shell\",\"arguments\":{\"command\":\"pwd\"}}</tool_call>",
        ),
        text_response("ä½ åœ¨ /home/user ç›®å½•"),
        text_response(r#"{"facts": []}"#),
    ]);

    let executor = Arc::new(MockExecutor::new("/home/user\n"));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor);

    let result = engine.think(user_event("æˆ‘åœ¨å“ª")).await.unwrap();

    // Final content should not contain tool_call tags
    assert!(!result.content.contains("tool_call"));
}

#[tokio::test]
async fn test_auto_mode_falls_back_to_text_parsing() {
    // In Auto mode, when no structured ToolUse is returned,
    // engine should fall back to parsing <tool_call> from text.
    let client = MockLlmClient::new(vec![
        text_response(
            "<tool_call>{\"name\":\"shell\",\"arguments\":{\"command\":\"date\"}}</tool_call>",
        ),
        text_response("ç°åœ¨æ˜¯2026å¹´"),
        text_response(r#"{"facts": []}"#),
    ]);

    let executor = Arc::new(MockExecutor::new("2026-02-11\n"));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor);

    let result = engine.think(user_event("å‡ ç‚¹äº†")).await.unwrap();

    assert!(result.content.contains("2026"));
}

#[tokio::test]
async fn test_text_mode_tool_error_sent_as_text() {
    // When a text-parsed tool fails, the error is sent back as plain text
    let client = MockLlmClient::new(vec![
        text_response(
            "<tool_call>{\"name\":\"shell\",\"arguments\":{\"command\":\"bad_cmd\"}}</tool_call>",
        ),
        text_response("å‘½ä»¤å¤±è´¥äº†ï¼Œæ¢ä¸ªæ–¹å¼"),
        text_response(r#"{"facts": []}"#),
    ]);

    let executor = Arc::new(FailingExecutor::always_fail("command not found: bad_cmd"));
    let memory = Arc::new(MockMemory::new());
    let engine = build_engine_with_mocks(client, memory, executor as Arc<dyn mneme_os::Executor>);

    let result = engine.think(user_event("æ‰§è¡Œé”™è¯¯å‘½ä»¤")).await.unwrap();

    assert!(result.content.contains("å¤±è´¥") || !result.content.is_empty());
}
